#library(party) #cforest
library(caret)
library(mlr)
source("loopscount.R")
source("mirna_features.R")
source("overhangcount.R")
source("LogReg.R")
source("DataAnalysis_BK.R")
source("BinEval.R")
#library("rpart")
#library(AUC)
#library("S4Vectors")
#library("stats4")
#library("IRanges")
#library("XVector")
#library("Biostrings")
#####################################################################################################################################################################
#CANONICAL MIRNAs
canonical_data=read.csv("./Data/prep_names.csv", header=TRUE, stringsAsFactors = FALSE)
canonical_data=canonical_data[-c(380,702,720,813,889),]
mirna_input2=data.frame(hairpin_seq=canonical_data$hairpin_seq, db=canonical_data$dotbracket, fe=canonical_data$fe,
mature5p_seq=canonical_data$mature5p_seq, mature3p_seq=canonical_data$mature3p_seq, stringsAsFactors = FALSE)
canonical_mirna=mirna_features(mirna_input2,random=FALSE)
canonical_mirna$class=0
#MIRTRONS
mirtron_names=read.table("./Data/mirtron_names.txt")
Index=c()
for (i in 1:dim(mirtron_names)[1]){
index=grep(paste("^",mirtron_names[i,1],"$",sep=""),canonical_data$hairpin_name)
Index=rbind(Index,index)
}
mirtron_mirna=canonical_mirna[Index,]
canonical_mirna=canonical_mirna[-Index,]
mirtron_mirna$class=1
#TEST
test_data=read.csv("./Data/testdata.csv", header=TRUE, stringsAsFactors = FALSE)
test_data=test_data[-c(1,22,103,139,151,164,165,182,202),]
test_input1=data.frame(hairpin_seq=test_data$hairpin_seq, db=test_data$dotbracket, fe=test_data$fe,
mature5p_seq=test_data$mature5p_seq, mature3p_seq=test_data$mature3p_seq, stringsAsFactors = FALSE)
test_mirna=mirna_features(test_input1,random=FALSE)
test_mirna$class=1 #theoretically mirtrons
#RANDOM
random_data=read.csv("./Data/randomdata.csv", header=TRUE, stringsAsFactors = FALSE)
random_input=data.frame(hairpin_seq="T", mature5p_seq=random_data$mature5p_seq, mature3p_seq=random_data$mature3p_seq, stringsAsFactors = FALSE)
random_mirna=mirna_features(random_input,random=TRUE)
random_mirna$class=1
######################################################################################################
#Plots
source('mirnaplots.R')
#mirtronplots_mirna=mirnaplots(mirtron_mirna)
#canonicalplots_mirna=mirnaplots(canonical_mirna)
#testplots_mirna=mirnaplots(test_mirna)
P.values=data.frame(matrix(,nrow=dim(canonical_mirna)[2]-1,ncol=5))
sign=c('Not Significant','Significant')
for (i in 1:(dim(canonical_mirna)[2]-1)){
P.values[i,1]=wilcox.test(mirtron_mirna[,i],canonical_mirna[,i],alternative="two.sided")$p.value
P.values[i,2]=ks.test(mirtron_mirna[,i],canonical_mirna[,i],alternative="two.sided")$p.value
tukey=data.frame(input=c(mirtron_mirna[,i],canonical_mirna[,i]),classes=c(rep(1,dim(mirtron_mirna)[1]),rep(0,dim(canonical_mirna)[1])))
means=tapply(tukey$input,tukey$classes, mean)
ajuste <- lm( tukey$input ~ tukey$classes)
tukey.alpha=0.005
h=HSD.test(ajuste, 'tukey$classes',alpha=tukey.alpha)
P.values[i,3]=sign[length(levels(h$groups$M))]
P.values[i,4]=means[1]
P.values[i,5]=means[2]
}
rownames(P.values)=colnames(canonical_mirna[,1:(dim(canonical_mirna)[2]-1)])
colnames(P.values)=c('Wilcoxon','Kolmogorov-Smirnov',paste('Tukey',tukey.alpha),'Mirtron mean','Canonical mean')
cat("\nStatistical tests\n")
print(P.values)
####################################################################################################################################################################
#PCA
canonical_mirna$mature3pposition=NULL
canonical_mirna$mature5pposition=NULL
canonical_mirna$mature5p_U=NULL
canonical_mirna$mature3p_U=NULL
canonical_mirna$hairpin_U=NULL
mirtron_mirna$mature3pposition=NULL
mirtron_mirna$mature5pposition=NULL
mirtron_mirna$mature5p_U=NULL
mirtron_mirna$mature3p_U=NULL
mirtron_mirna$hairpin_U=NULL
random_mirna$mature5p_U=NULL
random_mirna$mature3p_U=NULL
random_mirna$hairpin_U=NULL
pcdata_ml=rbind(mirtron_mirna,canonical_mirna)
#pairs.panels(pcdata_ml)
# PCA canonical vs mirtron
pcdata=pcdata_ml[,-17]
pca=prcomp(pcdata, retx=TRUE, center=TRUE, scale=TRUE)
labels=factor(c(rep('mirtron',dim(mirtron_mirna)[1]),rep('canonical',dim(pcdata)[1]-dim(mirtron_mirna)[1])),levels=c('mirtron','canonical'))
g <- ggbiplot(pca, obs.scale = 1, var.scale = 1,
groups = labels, ellipse = F,
circle = F)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal',
legend.position = 'top')
print(g) #mirtron vs canonical
test_mirna$mature3pposition=NULL
test_mirna$mature5pposition=NULL
test_mirna$mature5p_U=NULL
test_mirna$mature3p_U=NULL
test_mirna$hairpin_U=NULL
# Added test
pcdata5=rbind(pcdata,test_mirna[,-17])
pca5=pca
pca5$x=scale(pcdata5, pca$center, pca$scale) %*% pca$rotation
rownames(pca5$x)=1:dim(pcdata5)[1]
labels=factor(c(rep('mirtron',dim(mirtron_mirna)[1]),rep('canonical',dim(pcdata5)[1]-dim(test_mirna)[1]-dim(mirtron_mirna)[1]),
rep('test',dim(pcdata5)[1]-dim(canonical_mirna)[1]-dim(mirtron_mirna)[1]))
,levels=c('mirtron','canonical','test'))
g2 <- ggbiplot(pca5, obs.scale = 1, var.scale = 1,
groups = labels, ellipse = F,
circle = F)
g2 <- g2 + scale_color_discrete(name = '')
g2 <- g2 + theme(legend.direction = 'horizontal',
legend.position = 'top')
print(g2)
#pca_new=PCA(pcdata)
#f1=fviz_contrib(pca_new,choice = "var", axes = 1)
#f2=fviz_contrib(pca_new,choice = "var", axes = 2)
#f1_2=fviz_contrib(pca_new,choice = "var", axes = 1:2)
#plot(f1)
#plot(f2)
#plot(f1_2)
#fviz_pca_var(pca_new, col.var="contrib") +
#  scale_color_gradient2(low="black", mid="blue",
#                        high="red", midpoint=6) + theme_minimal)
# 3d PCA
library(rgl)
plot3d(pca$x, col=pcdata_ml$class)
plot3d(pca$rotation, col=pcdata_ml$class)
pca$x
plot(pca$x)
plot3d(pca$rotation[,1:3], col=pcdata_ml$class)
plot3d(pca$x[,1:3], col=pcdata_ml$class)
plot3d(pc$scores[,1:3], col=iris$Species)
pc <- princomp(iris[,1:4], cor=TRUE, scores=TRUE)
plot3d(pc$scores[,1:3], col=iris$Species)
plot3d(pc$scores[,1:3])
plot3d(pca$x[,1:3])#, col=pcdata_ml$class)
plot3d(pca$x[,1:3]), col=as.factor(pcdata_ml$class))
plot3d(pca$x[,1:3], col=as.factor(pcdata_ml$class))
plot3d(pc$scores[,1:3], col=iris$Species)
iris$Species
iris$Species <- factor(iris$Species,
levels = c("versicolor","virginica","setosa"))
plot3d(pc$scores[,1:3], col=iris$Species)
plot3d(pca$x[,1:3], col=rainbow(1000))
source("LogReg.R")
pcdata_ml$class
as.factor(pcdata_ml$class)
cl <- as.factor(pcdata_ml$class)
cl
cl[1]
which(pcdata_ml == 1)
which(pcdata_ml$class == 1)
with(pcdata_ml, which(class == 1))
with(pcdata_ml, class[which(class == 1)])
with(pcdata_ml, class[which(class == 1)]) = "red"
j = replace(pcdata_ml, with(pcdata_ml, class[which(class == 1)]), "red")
with(pcdata_ml, class[which(class == 1)])
j = replace(pcdata_ml, with(pcdata_ml, which(class == 1)), "red")
j
j = replace(pcdata_ml$class, with(pcdata_ml, which(class == 1)), "red")
j
a
a
colors = replace(pcdata_ml$class, with(pcdata_ml, which(class == 1)), "red")
colors = replace(pcdata_ml$class, with(pcdata_ml, which(class == 0)), "blue")
plot3d(pca$x[,1:3], col=colors)
colors = replace(pcdata_ml$class, with(pcdata_ml, which(class == 1)), "red")
colors = replace(pcdata_ml$class, with(pcdata_ml, which(class == 0)), "blue")
plot3d(pca$x[,1:3], col=colors)
plot3d(pca$x[,1:3], col=colors, size = 2)
library(rgl)
plot3d(pca$x[,1:3], col=colors, size = 5)
print(g) #mirtron vs canonical
colors = replace(pcdata_ml$class, with(pcdata_ml, which(class == 1)), "cyan")
colors = replace(pcdata_ml$class, with(pcdata_ml, which(class == 0)), "red")
plot3d(pca$x[,1:3], col=colors, size = 5)
set.seed(23)
source("LogReg.R")
cat("\n1x5-fold Cross-validation classification\n")
x=LogReg(pcdata_ml, itnumber=5)
print(x[[1]])
x=LogReg(pcdata_ml, itnumber=5)
pcdata_ml
View(overhangcount)
Z = pcdata_ml
itnumber = 3
X=BK_sample_crossVal(dim(Z)[1],itnumber)
LR=data.frame(Sensitivity=double(),Specificity=double(),F1=double(),AUC=double(), MCC=double())
RF=LR
LDA=LR
DT=LR
SVM=LR
NB=LR
for (i in 1:itnumber){
testing_data=Z[X[[i]],]
learning_data=Z[-X[[i]],]
check=testing_data$class
testing_data$class=NULL
# LOGISTIC REGRESSION
model=glm(class~.,data=learning_data, family="binomial")
model_pred_probs=predict(model, testing_data,type="response")
model_results=rep(0,dim(testing_data)[1])
model_results[model_pred_probs >(0.5)]=1
df=data.frame(model_pred_probs, check)
LR[i,]=BinEval(df)
#RANDOM FOREST; default ntree=500
rfm=randomForest(as.factor(class)~ ., learning_data, importance=TRUE)
rfm_results=predict(rfm,testing_data)#, OOB = TRUE)
df=data.frame(as.double(rfm_results)-1, check)
table(rfm_results,check)
RF[i,]=BinEval(df)
#LDA
ldam=lda(class~.,data=learning_data)
ldam_results=predict(ldam,testing_data)$class
df=data.frame(as.double(ldam_results)-1, check)
LDA[i,]=BinEval(df)
#Decision Tree
tree=tree(as.factor(class)~.,learning_data)
tree_results=predict(tree, testing_data, type="class")
df=data.frame(as.double(tree_results)-1, check)
#pruned_tree=prune.misclass(tree, best=8) #pruning
#pruned_tree_results=predict(pruned_tree, testing_data, type="class")
#df=data.frame(as.double(pruned_tree_results)-1, check)
DT[i,]=BinEval(df)
#print(DT[i,])
#SVM
svm_model=svm(as.factor(class)~.,data=learning_data)
svm_results=predict(svm_model,testing_data,type="class")
df=data.frame(as.double(svm_results)-1, check)
#tuned=tune(svm, as.factor(class)~.,data=learning_data, ranges = list(epsilon = seq(0,0.2,0.01), cost = c(0.001,0.01,.1,1,10,100)))
SVM[i,]=BinEval(df)
#Naive Bayes
nb=naiveBayes(as.factor(class)~.,data=learning_data)
nb_results=predict(nb, testing_data,type="class")
df=data.frame(as.double(nb_results)-1, check)
NB[i,]=BinEval(df)
}
LR[i,]=BinEval(df)
df
pred=prediction(df[1],df[2])
auc=performance(pred, "auc")
auc=performance(pred, "auc")
pred=Prediction(df[1],df[2])
auc=performance(pred, "auc")
pred=prediction(df[1],df[2])
auc=performance(pred, "auc")
pred
pred=ROCR::prediction(df[1],df[2])
auc=performance(pred, "auc")
auc=ROCR::performance(pred, "auc")
pred=ROCR::prediction(df[1],df[2])
auc=ROCR::performance(pred, "auc")
source("BinEval.R")
x=LogReg(pcdata_ml, itnumber=5)
print(x[[1]])
pred=predict(x[[3]],test_mirna) #predict on svm model
table(pred)
x=LogReg(pcdata_ml, itnumber=5)
print(x[[1]])
source("LogReg.R")
cat("\n1x5-fold Cross-validation classification\n")
x=LogReg(pcdata_ml, itnumber=5)
print(x[[1]])
x=LogReg(pcdata_ml, itnumber=5)
print(x[[1]])
pred=predict(x[[3]],test_mirna) #predict on svm model
pred=predict(x[[3]],test_mirna) #predict on svm model
table(pred)
Singlef=data.frame()
for (i in 1:(dim(pcdata_ml)[2]-1)){
singlef=LogReg(pcdata_ml[,c(i,dim(pcdata_ml)[2])],3)
Singlef=rbind(Singlef,singlef[[1]][5,])
}
rownames(Singlef)=colnames(pcdata)
colnames(Singlef)=colnames(singlef[[1]])
ord=with(Singlef,order(-AUC))
Singlef=Singlef[ord,]
print(Singlef)
svmProfile<-rfe(trx,try,sizes=c(1:3),
+             rfeControl=rfeControl(functions=caretFuncs,method="cv",
+             verbose=F,returnResamp="final",number=10),
+             method="svmRadial",tuneLength=5)
svmProfile<-rfe(trx,try,sizes=c(1:3),
rfeControl=rfeControl(functions=caretFuncs,method="cv",
verbose=F,returnResamp="final",number=10),
method="svmRadial",tuneLength=5)
svmProfile<-rfe(pcdata_ml[,1:16],as.factor(pcdata_ml[,17]),sizes=c(1:3),
rfeControl=rfeControl(functions=caretFuncs,method="cv",
verbose=F,returnResamp="final",number=10),
method="svmRadial",tuneLength=5)
svmProfile<-rfe(pcdata_ml[,1:3],as.factor(pcdata_ml[,17]),sizes=c(1:3),
rfeControl=rfeControl(functions=caretFuncs,method="cv",
verbose=F,number=3),
method="svmLinear")
IND.svm <- rfe(iris[,-1],iris$Species,
sizes = c(2, 5, 10,30),
rfeControl = rfeControl(functions = caretFuncs,
verbose = FALSE,method = "cv", number = 3),
method = "svmRadial")
iris
IND.svm <- rfe(iris[,-5],iris$Species,
sizes = c(1,2,3,4),
rfeControl = rfeControl(functions = caretFuncs,
verbose = FALSE,method = "cv", number = 3),
method = "svmRadial")
plot(results)
results = IND.svm
plot(results)
predictors(results)
plot(results, type=c("g", "o"))
IND.svm <- rfe(iris[,-5],iris$Species,
sizes = c(1,2,3,4),
rfeControl = rfeControl(functions = caretFuncs,
verbose = FALSE,method = "cv", number = 3),
method = "svmLinear")
results = IND.svm
plot(results)
predictors(results)
plot(results, type=c("g", "o"))
IND.svm <- rfe(iris[,-5],iris$Species,
sizes = c(1,2,3,4),
rfeControl = rfeControl(functions = caretFuncs,
verbose = FALSE,method = "cv", number = 3),
method = "svmRadial")
iris$Species
iris$Species[1]
type(iris$Species[1])
typeof(iris$Species[1])
svmProfile<-rfe(pcdata_ml[,1:3],as.factor(as.character(pcdata_ml[,17])),sizes=c(1:3),
rfeControl = rfeControl(functions = caretFuncs,
verbose = FALSE, method = "cv", number = 3),
method = "svmRadial")
pcdata_ml[,1:3]
as.factor(as.character(pcdata_ml[,17]))
svmProfile<-rfe(pcdata_ml[,1:3],as.factor(as.character(pcdata_ml[,17])),sizes=c(1,2,3),
rfeControl = rfeControl(functions = caretFuncs,
verbose = FALSE, method = "cv", number = 3),
method = "svmRadial")
svmProfile<-rfe(pcdata_ml[,6:8],as.factor(as.character(pcdata_ml[,17])),sizes=c(1,2,3),
rfeControl = rfeControl(functions = caretFuncs,
verbose = FALSE, method = "cv", number = 3),
method = "svmRadial")
IND.svm <- rfe(iris[,-5],iris$Species,
sizes = c(1,2,3,4),
rfeControl = rfeControl(functions = caretFuncs,
verbose = FALSE, method = "cv", number = 3),
method = "svmRadial")
with(pcdata_ml, which(class = 1))
classes = replace(pcdata_ml$class, with(pcdata_ml, which(class == 1)), "mirtron")
classes = replace(pcdata_ml$class, with(pcdata_ml, which(class == 0)), "canonical")
classes
classes = replace(pcdata_ml$class, with(pcdata_ml, which(class == "1")), "mirtron")
classes = replace(pcdata_ml$class, with(pcdata_ml, which(class == "0")), "canonical")
classes
colors = replace(pcdata_ml$class, with(pcdata_ml, which(class == 1)), "cyan")
colors = replace(colors,which(colors== 0), "red")
plot3d(pca$x[,1:3], col=colors, size = 5)
colors = replace(pcdata_ml$class, with(pcdata_ml, which(class == 1)), "blue")
colors = replace(colors,which(colors== 0), "red")
plot3d(pca$x[,1:3], col=colors, size = 5)
classes = replace(pcdata_ml$class, with(pcdata_ml, which(class == "1")), "mirtron")
classes = replace(classes, which(classes == "0"), "canonical")
classes
svmProfile<-rfe(pcdata_ml[,6:8],as.factor(classes),sizes=c(1,2,3),
rfeControl = rfeControl(functions = caretFuncs,
verbose = FALSE, method = "cv", number = 3),
method = "svmRadial")
plot(svmProfile)
predictors(svmProfile)
svmProfile <-rfe(pcdata, as.factor(classes),sizes=c(1:16),
rfeControl = rfeControl(functions = caretFuncs,
verbose = FALSE, method = "cv", number = 3),
method = "svmRadial")
plot(svmProfile)
predictors(svmProfile)
plot(svmProfile, type=c("g", "o"))
imp2=getImpRfGini(pcdata_ml[,-17],pcdata_ml$class)
ord=order(-as.double(imp2))
Imp=data.frame(RFBoruta=names(imp2)[order(-as.double(imp2))][1:length(predictors(results))],RFrfe = predictors(results))
cat("\nImportance by random forest using Boruta package and RFE\n")
print(Imp)
Imp=data.frame(RFBoruta=names(imp2)[order(-as.double(imp2))][1:length(predictors(rsvmProfile))],RFrfe = predictors(svmProfile))
Imp=data.frame(RFBoruta=names(imp2)[order(-as.double(imp2))][1:length(predictors(svmProfile))],RFrfe = predictors(svmProfile))
cat("\nImportance by random forest using Boruta package and RFE\n")
print(Imp)
install.packages("TunePareto")
library(TunePareto)
generateCVRuns(classes, ntimes = 1, nfold = 3, stratified = TRUE)
fold generateCVRuns(classes, ntimes = 1, nfold = 3, stratified = TRUE)
folds =
()
folds = generateCVRuns(classes, ntimes = 1, nfold = 3, stratified = TRUE)
folds
folds > 2016
folds[[1]] > 2016
folds[[1]] > 216
as.num(folds[[1]]) > 216
as.number(folds[[1]]) > 216
as.integer(folds[[1]])
folds[[1]]
folds[[1]][[1]]
folds[[1]][[1]] > 216
mean(folds[[1]][[1]] > 216)
mean(folds[[1]][[1]] > 216)
mean(folds[[1]][[2]] > 216)
mean(folds[[1]][[3]] > 216)
folds[[1]]
folds[[1]][[2]]
sum(folds[[1]][[3]] > 216)
sum(folds[[1]][[2]] > 216)
sum(folds[[1]][[1]] > 216)
folds
folds$`Run  1`$`Fold  1`
folds = generateCVRuns(classes, ntimes = 1, nfold = 3, stratified = FALSE)
mean(folds[[1]][[1]] > 216)
mean(folds[[1]][[2]] > 216)
mean(folds[[1]][[3]] > 216)
Z
set.seed(23)
LR=data.frame(Sensitivity=double(),Specificity=double(),F1=double(),AUC=double(), MCC=double())
RF=LR
LDA=LR
DT=LR
SVM=LR
NB=LR
folds = generateCVRuns(classes, ntimes = 1, nfold = 3, stratified = TRUE)
testing_data=Z[folds[[1]][[i]],]
learning_data=Z[-folds[[1]][[i]],]
length(folds)
length(folds[[1]])
i
i=1
testing_data=Z[folds[[1]][[i]],]
learning_data=Z[-folds[[1]][[i]],]
check=testing_data$class
testing_data$class=NULL
model=glm(class~.,data=learning_data, family="binomial")
model_pred_probs=predict(model, testing_data,type="response")
model_results=rep(0,dim(testing_data)[1])
model_results[model_pred_probs >(0.5)]=1
df=data.frame(model_pred_probs, check)
LR[i,]=BinEval(df)
LR
source("LogReg.R")
source("LogReg.R")
cat("\n1x5-fold Cross-validation classification\n")
x=LogReg(pcdata_ml, itnumber=5)
print(x[[1]])
source("LogReg.R")
cat("\n1x5-fold Cross-validation classification\n")
x=LogReg(pcdata_ml, itnumber=5)
print(x[[1]])
x=LogReg(pcdata_ml, itnumber=5)
print(x[[1]])
x=LogReg(pcdata_ml, itnumber=10)
print(x[[1]])
with(pcdata_ml, predictors(svmProfile) )
pcdata_ml$predictors(svmProfile)
pcdata_ml[,predictors(svmProfile)]
merge(pcdata_ml[,predictors(svmProfile)]pcdata_ml$class)
merge(pcdata_ml[,predictors(svmProfile)],pcdata_ml$class)
cbind(pcdata_ml[,predictors(svmProfile)],pcdata_ml$class)
top_feat = cbind(pcdata_ml[,predictors(svmProfile)],pcdata_ml$class)
cat("\n1x5-fold Cross-validation classification\n")
x=LogReg(top_feat, itnumber=10)
typeof(top_feat)
class(top_feat)
class(pcdata-Ml)
class(pcdata_ml)
Z=top_feat
LR=data.frame(Sensitivity=double(),Specificity=double(),F1=double(),AUC=double(), MCC=double())
RF=LR
LDA=LR
DT=LR
SVM=LR
NB=LR
folds = generateCVRuns(classes, ntimes = 1, nfold = itnumber, stratified = TRUE)
i
testing_data=Z[folds[[1]][[i]],]
learning_data=Z[-folds[[1]][[i]],]
check=testing_data$class
testing_data$class=NULL
model=glm(class~.,data=learning_data, family="binomial")
model_pred_probs=predict(model, testing_data,type="response")
model=glm(class~.,data=learning_data, family="binomial")
learning_data
class
folds = generateCVRuns(classes, ntimes = 1, nfold = itnumber, stratified = TRUE)
testing_data=Z[folds[[1]][[i]],]
learning_data=Z[-folds[[1]][[i]],]
check=testing_data$class
testing_data$class=NULL
model=glm(class~.,data=learning_data, family="binomial")
model=glm(learnign_data$class~.,data=learning_data, family="binomial")
model=glm(learning_data$class~.,data=learning_data, family="binomial")
learning_data
View(learning_data)
top_feat = cbind(pcdata_ml[,predictors(svmProfile)],class = pcdata_ml$class)
cat("\n1x5-fold Cross-validation classification\n")
x=LogReg(top_feat, itnumber=10)
cat("\n1x5-fold Cross-validation classification\n")
x=LogReg(top_feat, itnumber=10)
print(x[[1]])
x=LogReg(pcdata_ml, itnumber=10)
print(x[[1]])
x=LogReg(top_feat, itnumber=10)
print(x[[1]])
